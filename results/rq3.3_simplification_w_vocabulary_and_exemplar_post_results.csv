Corpus,Scenario,Threat Model,Defense Model,accuracy@1 ↓,accuracy@5 ↓,true_class_confidence ↓,entropy ↑,pinc ↑,bertscore ↑,meteor ↑
EBG,simplification w vocabulary and exemplar,logreg,Gemma-2,"0.020 ± 0.020 [0.002, 0.049]","0.094 ± 0.035 [0.039, 0.157]","0.039 ± 0.023 [0.009, 0.077]","2.247 ± 0.089 [2.073, 2.411]","0.909 ± 0.002 [0.905, 0.913]","0.484 ± 0.004 [0.477, 0.491]","0.138 ± 0.003 [0.133, 0.143]"
EBG,simplification w vocabulary and exemplar,logreg,Llama-3.1,"0.050 ± 0.037 [0.007, 0.113]","0.121 ± 0.036 [0.058, 0.187]","0.059 ± 0.028 [0.019, 0.110]","2.706 ± 0.083 [2.547, 2.859]","0.911 ± 0.002 [0.907, 0.915]","0.488 ± 0.004 [0.481, 0.494]","0.150 ± 0.003 [0.145, 0.155]"
EBG,simplification w vocabulary and exemplar,logreg,Ministral,"0.022 ± 0.025 [0.002, 0.056]","0.126 ± 0.038 [0.062, 0.202]","0.048 ± 0.026 [0.011, 0.092]","2.107 ± 0.088 [1.936, 2.270]","0.909 ± 0.003 [0.905, 0.914]","0.476 ± 0.004 [0.470, 0.484]","0.110 ± 0.003 [0.105, 0.115]"
EBG,simplification w vocabulary and exemplar,logreg,Claude-3.5,"0.185 ± 0.044 [0.106, 0.270]","0.517 ± 0.059 [0.404, 0.629]","0.161 ± 0.041 [0.089, 0.238]","2.294 ± 0.081 [2.136, 2.444]","0.789 ± 0.004 [0.782, 0.796]","0.671 ± 0.004 [0.664, 0.678]","0.250 ± 0.004 [0.243, 0.259]"
EBG,simplification w vocabulary and exemplar,logreg,GPT-4o,"0.319 ± 0.055 [0.215, 0.423]","0.619 ± 0.055 [0.516, 0.724]","0.240 ± 0.049 [0.147, 0.328]","2.546 ± 0.091 [2.382, 2.723]","0.615 ± 0.007 [0.601, 0.627]","0.769 ± 0.004 [0.761, 0.778]","0.427 ± 0.008 [0.412, 0.442]"
EBG,simplification w vocabulary and exemplar,svm,Gemma-2,"0.022 ± 0.022 [0.002, 0.055]","0.154 ± 0.041 [0.081, 0.232]","0.043 ± 0.023 [0.010, 0.084]","3.511 ± 0.071 [3.385, 3.649]","0.909 ± 0.002 [0.905, 0.913]","0.484 ± 0.004 [0.477, 0.491]","0.138 ± 0.003 [0.133, 0.143]"
EBG,simplification w vocabulary and exemplar,svm,Llama-3.1,"0.043 ± 0.030 [0.007, 0.095]","0.167 ± 0.043 [0.090, 0.251]","0.054 ± 0.026 [0.013, 0.098]","3.982 ± 0.047 [3.891, 4.069]","0.911 ± 0.002 [0.907, 0.915]","0.488 ± 0.004 [0.481, 0.494]","0.150 ± 0.003 [0.145, 0.155]"
EBG,simplification w vocabulary and exemplar,svm,Ministral,"0.038 ± 0.028 [0.006, 0.085]","0.165 ± 0.043 [0.090, 0.246]","0.051 ± 0.024 [0.015, 0.093]","3.320 ± 0.060 [3.207, 3.432]","0.909 ± 0.003 [0.905, 0.914]","0.476 ± 0.004 [0.470, 0.484]","0.110 ± 0.003 [0.105, 0.115]"
EBG,simplification w vocabulary and exemplar,svm,Claude-3.5,"0.239 ± 0.050 [0.152, 0.338]","0.393 ± 0.057 [0.289, 0.508]","0.118 ± 0.036 [0.053, 0.181]","4.062 ± 0.041 [3.989, 4.144]","0.789 ± 0.004 [0.782, 0.796]","0.671 ± 0.004 [0.664, 0.678]","0.250 ± 0.004 [0.243, 0.259]"
EBG,simplification w vocabulary and exemplar,svm,GPT-4o,"0.388 ± 0.058 [0.281, 0.502]","0.607 ± 0.058 [0.492, 0.711]","0.168 ± 0.043 [0.091, 0.247]","4.197 ± 0.042 [4.119, 4.276]","0.615 ± 0.007 [0.601, 0.627]","0.769 ± 0.004 [0.761, 0.778]","0.427 ± 0.008 [0.412, 0.442]"
EBG,simplification w vocabulary and exemplar,roberta,Gemma-2,"0.014 ± 0.019 [0.001, 0.037]","0.097 ± 0.034 [0.042, 0.161]","0.030 ± 0.021 [0.006, 0.064]","2.099 ± 0.088 [1.937, 2.264]","0.909 ± 0.002 [0.905, 0.913]","0.484 ± 0.004 [0.477, 0.491]","0.138 ± 0.003 [0.133, 0.143]"
EBG,simplification w vocabulary and exemplar,roberta,Llama-3.1,"0.014 ± 0.019 [0.001, 0.037]","0.087 ± 0.032 [0.034, 0.148]","0.029 ± 0.020 [0.005, 0.062]","1.686 ± 0.079 [1.540, 1.837]","0.911 ± 0.002 [0.907, 0.915]","0.488 ± 0.004 [0.481, 0.494]","0.150 ± 0.003 [0.145, 0.155]"
EBG,simplification w vocabulary and exemplar,roberta,Ministral,"0.014 ± 0.019 [0.001, 0.037]","0.102 ± 0.034 [0.043, 0.165]","0.029 ± 0.019 [0.005, 0.061]","1.640 ± 0.082 [1.490, 1.798]","0.909 ± 0.003 [0.905, 0.914]","0.476 ± 0.004 [0.470, 0.484]","0.110 ± 0.003 [0.105, 0.115]"
EBG,simplification w vocabulary and exemplar,roberta,Claude-3.5,"0.452 ± 0.058 [0.339, 0.557]","0.608 ± 0.056 [0.502, 0.714]","0.400 ± 0.057 [0.296, 0.512]","1.801 ± 0.081 [1.650, 1.953]","0.789 ± 0.004 [0.782, 0.796]","0.671 ± 0.004 [0.664, 0.678]","0.250 ± 0.004 [0.243, 0.259]"
EBG,simplification w vocabulary and exemplar,roberta,GPT-4o,"0.548 ± 0.057 [0.445, 0.660]","0.707 ± 0.053 [0.608, 0.803]","0.529 ± 0.057 [0.418, 0.637]","1.476 ± 0.079 [1.337, 1.632]","0.615 ± 0.007 [0.601, 0.627]","0.769 ± 0.004 [0.761, 0.778]","0.427 ± 0.008 [0.412, 0.442]"
RJ,simplification w vocabulary and exemplar,logreg,Claude-3.5,"0.180 ± 0.047 [0.095, 0.267]","0.352 ± 0.058 [0.247, 0.465]","0.164 ± 0.043 [0.087, 0.244]","0.881 ± 0.079 [0.737, 1.033]","0.747 ± 0.005 [0.737, 0.757]","0.710 ± 0.006 [0.699, 0.720]","0.292 ± 0.006 [0.281, 0.303]"
RJ,simplification w vocabulary and exemplar,logreg,Ministral,"0.046 ± 0.039 [0.004, 0.111]","0.243 ± 0.054 [0.145, 0.344]","0.071 ± 0.031 [0.022, 0.125]","0.700 ± 0.094 [0.536, 0.887]","0.870 ± 0.004 [0.862, 0.877]","0.539 ± 0.006 [0.529, 0.550]","0.136 ± 0.005 [0.128, 0.145]"
RJ,simplification w vocabulary and exemplar,logreg,GPT-4o,"0.207 ± 0.048 [0.124, 0.300]","0.406 ± 0.058 [0.298, 0.517]","0.192 ± 0.045 [0.114, 0.279]","1.003 ± 0.100 [0.806, 1.182]","0.588 ± 0.008 [0.573, 0.603]","0.791 ± 0.006 [0.780, 0.801]","0.422 ± 0.009 [0.405, 0.439]"
RJ,simplification w vocabulary and exemplar,logreg,Gemma-2,"0.046 ± 0.040 [0.005, 0.111]","0.243 ± 0.051 [0.144, 0.333]","0.069 ± 0.033 [0.020, 0.124]","1.121 ± 0.095 [0.943, 1.297]","0.870 ± 0.004 [0.863, 0.878]","0.539 ± 0.006 [0.528, 0.550]","0.178 ± 0.005 [0.169, 0.187]"
RJ,simplification w vocabulary and exemplar,logreg,Llama-3.1,"0.117 ± 0.037 [0.053, 0.185]","0.245 ± 0.050 [0.157, 0.344]","0.083 ± 0.033 [0.032, 0.146]","1.193 ± 0.098 [1.017, 1.383]","0.873 ± 0.004 [0.866, 0.880]","0.546 ± 0.006 [0.535, 0.557]","0.197 ± 0.005 [0.188, 0.206]"
RJ,simplification w vocabulary and exemplar,svm,Claude-3.5,"0.135 ± 0.041 [0.065, 0.214]","0.324 ± 0.055 [0.215, 0.421]","0.091 ± 0.033 [0.036, 0.150]","3.448 ± 0.026 [3.398, 3.497]","0.747 ± 0.005 [0.737, 0.757]","0.710 ± 0.006 [0.699, 0.720]","0.292 ± 0.006 [0.281, 0.303]"
RJ,simplification w vocabulary and exemplar,svm,Ministral,"0.059 ± 0.042 [0.007, 0.131]","0.208 ± 0.049 [0.123, 0.302]","0.082 ± 0.032 [0.031, 0.142]","3.059 ± 0.069 [2.930, 3.188]","0.870 ± 0.004 [0.862, 0.877]","0.539 ± 0.006 [0.529, 0.550]","0.136 ± 0.005 [0.128, 0.145]"
RJ,simplification w vocabulary and exemplar,svm,GPT-4o,"0.079 ± 0.050 [0.014, 0.169]","0.388 ± 0.057 [0.285, 0.501]","0.092 ± 0.033 [0.036, 0.151]","3.527 ± 0.026 [3.476, 3.575]","0.588 ± 0.008 [0.573, 0.603]","0.791 ± 0.006 [0.780, 0.801]","0.422 ± 0.009 [0.405, 0.439]"
RJ,simplification w vocabulary and exemplar,svm,Gemma-2,"0.083 ± 0.031 [0.031, 0.139]","0.181 ± 0.045 [0.102, 0.270]","0.079 ± 0.030 [0.030, 0.134]","3.255 ± 0.043 [3.177, 3.337]","0.870 ± 0.004 [0.863, 0.878]","0.539 ± 0.006 [0.528, 0.550]","0.178 ± 0.005 [0.169, 0.187]"
RJ,simplification w vocabulary and exemplar,svm,Llama-3.1,"0.060 ± 0.042 [0.007, 0.133]","0.223 ± 0.050 [0.133, 0.321]","0.075 ± 0.029 [0.027, 0.128]","3.295 ± 0.034 [3.232, 3.359]","0.873 ± 0.004 [0.866, 0.880]","0.546 ± 0.006 [0.535, 0.557]","0.197 ± 0.005 [0.188, 0.206]"
RJ,simplification w vocabulary and exemplar,roberta,Claude-3.5,"0.090 ± 0.033 [0.032, 0.149]","0.414 ± 0.058 [0.305, 0.523]","0.078 ± 0.031 [0.027, 0.132]","1.406 ± 0.093 [1.228, 1.577]","0.747 ± 0.005 [0.737, 0.757]","0.710 ± 0.006 [0.699, 0.720]","0.292 ± 0.006 [0.281, 0.303]"
RJ,simplification w vocabulary and exemplar,roberta,Ministral,"0.052 ± 0.040 [0.009, 0.115]","0.190 ± 0.048 [0.105, 0.282]","0.065 ± 0.029 [0.022, 0.119]","1.459 ± 0.081 [1.310, 1.613]","0.870 ± 0.004 [0.862, 0.877]","0.539 ± 0.006 [0.529, 0.550]","0.136 ± 0.005 [0.128, 0.145]"
RJ,simplification w vocabulary and exemplar,roberta,GPT-4o,"0.135 ± 0.042 [0.063, 0.211]","0.379 ± 0.057 [0.272, 0.485]","0.118 ± 0.036 [0.052, 0.183]","1.411 ± 0.086 [1.253, 1.577]","0.588 ± 0.008 [0.573, 0.603]","0.791 ± 0.006 [0.780, 0.801]","0.422 ± 0.009 [0.405, 0.439]"
RJ,simplification w vocabulary and exemplar,roberta,Gemma-2,"0.074 ± 0.030 [0.026, 0.126]","0.223 ± 0.050 [0.133, 0.319]","0.068 ± 0.031 [0.021, 0.118]","1.607 ± 0.086 [1.451, 1.773]","0.870 ± 0.004 [0.863, 0.878]","0.539 ± 0.006 [0.528, 0.550]","0.178 ± 0.005 [0.169, 0.187]"
RJ,simplification w vocabulary and exemplar,roberta,Llama-3.1,"0.074 ± 0.030 [0.026, 0.126]","0.237 ± 0.049 [0.151, 0.334]","0.067 ± 0.029 [0.022, 0.119]","1.472 ± 0.087 [1.312, 1.640]","0.873 ± 0.004 [0.866, 0.880]","0.546 ± 0.006 [0.535, 0.557]","0.197 ± 0.005 [0.188, 0.206]"
